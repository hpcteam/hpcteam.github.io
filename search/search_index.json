{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Ayyappaswamy Eethakota","text":"<p>Linux Systems Administrator and High-Performance Computing (HPC) Engineer with hands-on experience supporting large-scale, production-grade HPC environments for government and enterprise research workloads.</p> <p>This site documents my professional experience, technical skills, and operational knowledge gained while working on multi-petaflop HPC infrastructure, GPU-accelerated clusters, high-speed InfiniBand networks, and enterprise Linux systems.</p>"},{"location":"#professional-overview","title":"Professional Overview","text":"<p>I support and operate large-scale Linux and HPC environments used for mission-critical research and engineering workloads. My responsibilities include cluster administration, job scheduling, performance benchmarking, monitoring, automation, and incident management across CPU and GPU-based systems.</p> <p>I have contributed to the deployment and sustained operation of India\u2019s multi-petaflops HPC infrastructure, supporting environments with over 1,200 compute nodes and NVIDIA H100 GPU accelerators.</p>"},{"location":"#areas-of-work","title":"Areas of Work","text":"<ul> <li>Linux system administration in multi-node HPC environments  </li> <li>HPC cluster operations using NVIDIA Bright Cluster Manager  </li> <li>Workload scheduling and execution using PBS Pro and Slurm  </li> <li>GPU-enabled compute platforms and NVIDIA software stack  </li> <li>High-speed InfiniBand (400 Gb/s) networking  </li> <li>Performance benchmarking using HPL, LINPACK, and HPCC  </li> <li>Automation using shell scripting  </li> <li>Hardware, firmware, and datacenter operations  </li> <li>24\u00d77 L2 production support and incident handling  </li> </ul>"},{"location":"#operational-knowledge-base","title":"Operational Knowledge Base","text":"<p>This site includes a detailed collection of real-world operational issues and troubleshooting scenarios encountered in production environments, such as:</p> <ul> <li>User access, SSH, and network connectivity issues  </li> <li>Job scheduling, queue, and execution failures  </li> <li>Benchmarking and performance validation errors  </li> <li>GPU driver, CUDA, and accelerator-related issues  </li> <li>Cluster management and licensing problems  </li> <li>InfiniBand fabric and communication issues  </li> <li>Hardware-level faults (disk, NIC, DIMM, CPU)  </li> <li>Software installation and compilation errors  </li> </ul> <p>These scenarios are documented to reflect practical problem-solving approaches used in enterprise HPC operations.</p>"},{"location":"#purpose-of-this-site","title":"Purpose of This Site","text":"<p>The purpose of this documentation is to:</p> <ul> <li>Present my professional background in a structured manner  </li> <li>Demonstrate hands-on experience with HPC and Linux systems  </li> <li>Serve as a personal technical knowledge base  </li> <li>Support interview discussions and technical evaluations  </li> </ul>"},{"location":"#navigation","title":"Navigation","text":"<p>Use the navigation menu to explore detailed sections covering:</p> <ul> <li>Professional Overview and Experience  </li> <li>Technical Skills  </li> <li>Machines, Hardware, and Networks  </li> <li>Projects and Contributions  </li> <li>Roles and Responsibilities  </li> <li>HPC Operational Issues and Troubleshooting  </li> <li>Education and Contact Information  </li> </ul>"},{"location":"Professional-Summary/","title":"Professional Overview","text":"<p>I am a Linux Systems Administrator and HPC Engineer with nearly two years of hands-on experience supporting large-scale high-performance computing (HPC) environments used for government and enterprise research workloads. My work focuses on operating and maintaining production-grade HPC infrastructure, where reliability, performance consistency, and availability are critical.</p> <p>I have contributed to the deployment and sustained operation of India\u2019s 11-Petaflops supercomputing infrastructure, working on environments comprising 1,200+ compute nodes and NVIDIA H100 GPU accelerator systems. My responsibilities include cluster provisioning, operating system management, workload scheduling, monitoring, and troubleshooting across CPU and GPU-based clusters.</p>"},{"location":"Professional-Summary/#what-i-do","title":"What I Do","text":"<p>In my current role at TIS Labs Pvt. Ltd., I manage and support HPC systems using NVIDIA Bright Cluster Manager, handling:</p> <ul> <li>OS provisioning and node lifecycle management</li> <li>Scheduler integration and workload execution using PBS Pro</li> <li>Continuous monitoring and health validation</li> <li>User access control and system-level troubleshooting</li> </ul> <p>I work with monitoring platforms such as Bright Cluster Manager, Dell OpenManage Enterprise, and InfiniBand UFM to detect issues early and maintain high system availability (99.99%) in production environments.</p>"},{"location":"Professional-Summary/#performance-optimization","title":"Performance &amp; Optimization","text":"<p>I regularly perform cluster benchmarking and validation using HPL, LINPACK, and HPCC, ensuring that systems operate at expected performance levels. My work includes tuning configurations to maintain stable throughput and efficient resource utilization.</p> <p>I also support high-speed InfiniBand (400 Gb/s) networks, monitoring link health, resolving connectivity issues, and assisting in performance optimization for distributed workloads.</p>"},{"location":"Professional-Summary/#applications-hpc-software","title":"Applications &amp; HPC Software","text":"<p>I install, configure, and validate both commercial and open-source engineering applications across multi-node environments, including:</p> <ul> <li>ANSYS Fluent, ANSYS CFX, STAR-CCM+, HEEDS, Altair FEKO</li> <li>OpenFOAM, SU2, ParaView</li> </ul> <p>This includes MPI integration, environment module configuration, and ensuring stable application behavior on shared HPC systems. I work with compiler and library stacks such as AOCC, AOCL, GCC, OpenMPI, and Intel OneAPI to support consistent and reliable application builds.</p>"},{"location":"Professional-Summary/#automation-operations","title":"Automation &amp; Operations","text":"<p>Automation plays a key role in my daily work. I use shell scripting to streamline:</p> <ul> <li>OS installations and node provisioning</li> <li>User onboarding and access management</li> <li>Package deployment and environment setup</li> </ul> <p>These efforts have reduced manual administrative tasks, improved deployment efficiency, and lowered user-related support requests.</p>"},{"location":"Professional-Summary/#infrastructure-datacenter-work","title":"Infrastructure &amp; Datacenter Work","text":"<p>Alongside software operations, I am actively involved in hardware and datacenter activities, including:</p> <ul> <li>Server integration and validation</li> <li>BIOS, firmware, and driver updates</li> <li>Hardware troubleshooting on Dell PowerEdge platforms</li> </ul> <p>I also contributed to BSNL\u2019s datacenter modernization project, supporting server installation, network validation, and OS provisioning across multi-node environments.</p>"},{"location":"Professional-Summary/#operations-support","title":"Operations &amp; Support","text":"<p>I currently provide 24\u00d77 L2 operational support, handling incident diagnosis, root-cause analysis, corrective actions, and documentation in high-availability environments. My focus is on maintaining stable infrastructure, predictable performance, and a smooth experience for researchers and engineers running compute-intensive workloads.</p>"},{"location":"Professional-Summary/#focus-approach","title":"Focus &amp; Approach","text":"<p>My approach centers on stability, performance, and scalability. I aim to build and operate Linux and HPC environments that are reliable, well-monitored, and ready for demanding scientific and engineering workloads.</p>"},{"location":"applications-and-libraries/","title":"Applications &amp; Libraries","text":"<p>This page outlines the commercial applications, open-source software, and libraries/toolchains I have worked with while supporting production Linux and High-Performance Computing (HPC) environments. The focus includes installation, configuration, integration, and operational support across multi-node clusters.</p>"},{"location":"applications-and-libraries/#commercial-applications","title":"Commercial Applications","text":"<p>I have worked with the following commercial engineering and simulation applications in HPC environments. Responsibilities include installation, configuration, MPI integration, environment module setup, and runtime support for users.</p> <ul> <li>ANSYS Fluent</li> <li>ANSYS CFX</li> <li>STAR-CCM+</li> <li>HEEDS</li> <li>Altair FEKO</li> </ul> <p>Activities performed: - Installation and validation on multi-node HPC clusters - MPI and scheduler integration (PBS Pro / Slurm) - Environment module creation and maintenance - Supporting batch and interactive job execution - Troubleshooting runtime and performance-related issues</p>"},{"location":"applications-and-libraries/#open-source-applications","title":"Open-Source Applications","text":"<p>I have supported and operated the following open-source applications commonly used in scientific computing and research workloads.</p> <ul> <li>OpenFOAM</li> <li>SU2</li> <li>ParaView</li> <li>WRF</li> </ul> <p>Activities performed: - Source-based installation and configuration - MPI integration and multi-node execution testing - Environment setup and user support - Troubleshooting build, runtime, and scaling issues</p>"},{"location":"applications-and-libraries/#compilers-libraries-toolchains","title":"Compilers, Libraries &amp; Toolchains","text":"<p>I have worked with the following compilers and libraries to support application builds and runtime execution in HPC environments.</p>"},{"location":"applications-and-libraries/#compilers","title":"Compilers","text":"<ul> <li>AOCC (AMD Optimizing C/C++ Compiler)</li> <li>GCC</li> <li>Intel OneAPI Toolkit</li> </ul>"},{"location":"applications-and-libraries/#libraries-mpi","title":"Libraries &amp; MPI","text":"<ul> <li>AOCL (AMD Optimized CPU Libraries)</li> <li>OpenMPI</li> </ul> <p>Activities performed: - Application compilation and build validation - Library and compiler compatibility checks - Runtime library configuration - Supporting CPU and GPU-enabled workloads</p>"},{"location":"applications-and-libraries/#operational-scope","title":"Operational Scope","text":"<p>Across all applications and libraries, my responsibilities include:</p> <ul> <li>Installation and upgrade validation</li> <li>Dependency and compatibility checks</li> <li>Scheduler and resource manager integration</li> <li>Environment module management</li> <li>User support and issue resolution</li> <li>Coordination with infrastructure and application teams</li> </ul>"},{"location":"contact/","title":"Contact","text":""},{"location":"contact/#contact-information","title":"Contact Information","text":"<p>Name: Ayyappaswamy Eethakota Location: West Godavari, Andhra Pradesh, India  </p> <p> </p> <p> Download Resume</p> <p> Download Resume</p> <p> Download Resume</p>"},{"location":"education/","title":"Education","text":"<p>This section summarizes my academic background, which provides the foundational engineering and analytical knowledge supporting my work in Linux system administration and high-performance computing environments.</p>"},{"location":"education/#bachelor-of-technology-btech-mechanical-engineering","title":"Bachelor of Technology (B.Tech) \u2013 Mechanical Engineering","text":"<p>Akkula Gopayya College of Engineering, JNTUK 2016 \u2013 2020</p> <p>Completed undergraduate studies with a focus on core mechanical engineering principles, problem-solving methodologies, and analytical thinking. The program provided a strong foundation in engineering fundamentals, technical documentation, and structured approaches to complex systems.</p>"},{"location":"education/#diploma-mechanical-engineering","title":"Diploma \u2013 Mechanical Engineering","text":"<p>SMVM Polytechnic College, Tanuku 2013 \u2013 2016</p> <p>Completed diploma-level technical education covering mechanical systems, applied engineering practices, and hands-on laboratory work, contributing to practical engineering understanding and technical discipline.</p>"},{"location":"education/#secondary-school-certificate-ssc","title":"Secondary School Certificate (SSC)","text":"<p>ZPPH School, Koderu 2013</p> <p>Completed secondary education with emphasis on foundational mathematics, science, and structured learning essential for engineering studies.</p>"},{"location":"hpc-troubleshooting-notes/","title":"HPC Operational Issues &amp; Troubleshooting Scenarios","text":"<p>This page documents common operational issues, failure scenarios, and troubleshooting areas encountered while supporting large-scale Linux and High-Performance Computing (HPC) environments in production. The content is based on real-world cluster operations and incident handling.</p>"},{"location":"hpc-troubleshooting-notes/#1-user-access-connectivity-issues","title":"1. User Access &amp; Connectivity Issues","text":"<ul> <li>Users unable to access cluster nodes due to routing or network configuration issues</li> <li>IP address changes in mixed or static network environments causing connectivity loss</li> <li>Users unable to ping compute or management node IP addresses</li> <li>SSH, SCP, and file copy failures between cluster nodes</li> <li>Access issues caused by incorrect firewall rules or network policies</li> </ul>"},{"location":"hpc-troubleshooting-notes/#2-job-scheduling-execution-issues","title":"2. Job Scheduling &amp; Execution Issues","text":"<ul> <li>Jobs remaining in queue due to compute node unavailability</li> <li>Jobs failing due to incorrect software paths or environment configuration</li> <li>Jobs failing when assigned nodes become unresponsive</li> <li>Jobs entering held or stalled state due to time drift across compute nodes</li> <li>Scheduler-related issues affecting job start or completion</li> </ul>"},{"location":"hpc-troubleshooting-notes/#3-benchmarking-performance-issues","title":"3. Benchmarking &amp; Performance Issues","text":"<ul> <li>Benchmark tests failing on specific nodes due to mismatched firmware versions</li> <li>HPL benchmark failures on single nodes caused by:</li> <li>Slurm errors</li> <li>Munge service failures</li> <li>Munge key mismatches</li> <li>HPL benchmark failures due to time differences across nodes   (date or hardware clock mismatch)</li> <li>HPL calculation errors during benchmark execution</li> <li>Communication errors during multi-node benchmark runs</li> <li>Script-related issues in PBS or HPL execution scripts</li> </ul>"},{"location":"hpc-troubleshooting-notes/#4-gpu-nvidia-software-issues","title":"4. GPU &amp; NVIDIA Software Issues","text":"<ul> <li>NVIDIA driver installation failures</li> <li>Incorrect or incompatible driver versions installed</li> <li>Partial GPU visibility on GPU nodes (e.g., fewer GPUs detected than expected)</li> <li>Application failures due to CUDA, driver, or library mismatches</li> <li>GPU-related performance degradation due to configuration issues</li> </ul>"},{"location":"hpc-troubleshooting-notes/#5-cluster-management-licensing-issues","title":"5. Cluster Management &amp; Licensing Issues","text":"<ul> <li>Inability to access cluster management interfaces</li> <li>Issues while syncing or pushing cluster configuration changes</li> <li>UFM license-related issues</li> <li>UFM web portal access problems</li> <li>Bright Cluster Manager license issues</li> <li>Cluster lock conditions caused by license problems</li> <li>Unlocking and restoring cluster functionality after license resolution</li> </ul>"},{"location":"hpc-troubleshooting-notes/#6-network-fabric-issues","title":"6. Network &amp; Fabric Issues","text":"<ul> <li>InfiniBand fabric communication failures</li> <li>Nodes unable to communicate with license servers</li> <li>Network configuration issues impacting application communication</li> <li>Fabric-level issues affecting parallel workload performance</li> </ul>"},{"location":"hpc-troubleshooting-notes/#7-hardware-level-issues","title":"7. Hardware-Level Issues","text":"<ul> <li>Disk and root filesystem failures</li> <li>NIC card issues causing application or connectivity problems</li> <li>InfiniBand cable faults and physical connectivity issues</li> <li>DIMM errors detected during system operation</li> <li>CPU-related hardware errors impacting node stability</li> </ul>"},{"location":"hpc-troubleshooting-notes/#8-software-installation-compilation-issues","title":"8. Software Installation &amp; Compilation Issues","text":"<ul> <li>Compilation errors during application installation</li> <li>Installation failures caused by missing dependencies</li> <li>High-availability (HA) related errors leading to node issues</li> <li>Runtime failures caused by incorrect software paths</li> <li>Version mismatches between application components</li> </ul>"},{"location":"hpc-troubleshooting-notes/#9-documentation-operational-practices","title":"9. Documentation &amp; Operational Practices","text":"<ul> <li>Preparing dependency and prerequisite documentation before installations</li> <li>Capturing screenshots and logs during critical cluster changes</li> <li>Tracking configuration changes across cluster nodes</li> <li>Maintaining operational records for troubleshooting and audits</li> </ul>"},{"location":"hpc-troubleshooting-notes/#10-parallel-computing-concepts-reference-notes","title":"10. Parallel Computing Concepts (Reference Notes)","text":""},{"location":"hpc-troubleshooting-notes/#mpi-message-passing-interface","title":"MPI (Message Passing Interface)","text":"<ul> <li>Distributed memory programming model</li> <li>Scales across multiple nodes</li> <li>Used for inter-node communication in HPC workloads</li> </ul>"},{"location":"hpc-troubleshooting-notes/#openmp","title":"OpenMP","text":"<ul> <li>Shared memory programming model</li> <li>Used within a single compute node</li> <li>Suitable for multi-threaded computation</li> </ul> <p>MPI is commonly used for inter-node parallelism, while OpenMP is used for intra-node parallelism.</p>"},{"location":"hpc-troubleshooting-notes/#11-cpu-affinity-scheduler-concepts","title":"11. CPU Affinity &amp; Scheduler Concepts","text":"<ul> <li>CPU affinity configuration in Slurm</li> <li>Binding processes to specific CPU cores</li> <li>Benefits include improved cache locality and execution efficiency</li> </ul>"},{"location":"hpc-troubleshooting-notes/#common-slurm-options","title":"Common Slurm Options","text":"<ul> <li><code>--cpu-bind</code></li> <li><code>--threads-per-core</code></li> <li><code>--ntasks</code></li> <li><code>--cpus-per-task</code></li> </ul> <p>These options help control task placement and CPU utilization for performance-sensitive workloads.</p>"},{"location":"machines-hardware-networks/","title":"Machines, Hardware &amp; Networks","text":"<p>This section outlines the compute platforms, hardware infrastructure, and networking technologies I have supported while operating large-scale Linux and HPC environments in production.</p>"},{"location":"machines-hardware-networks/#compute-servers-platforms","title":"Compute Servers &amp; Platforms","text":"<p>I have hands-on experience working with enterprise-grade server platforms deployed for high-performance computing and enterprise workloads.</p>"},{"location":"machines-hardware-networks/#dell-poweredge-servers","title":"Dell PowerEdge Servers","text":"<ul> <li>Dell PowerEdge R6625</li> <li>Dell PowerEdge R7625</li> <li>Dell PowerEdge XE8640 (GPU-accelerated platform)</li> <li>Dell PowerEdge T550</li> </ul> <p>Responsibilities include server validation, operating system installation, firmware updates, hardware diagnostics, and operational support in production environments.</p>"},{"location":"machines-hardware-networks/#gpu-accelerator-hardware","title":"GPU &amp; Accelerator Hardware","text":"<p>I support GPU-enabled compute platforms used for compute-intensive and simulation workloads.</p> <ul> <li>NVIDIA H100 GPU accelerator nodes</li> <li>Multi-GPU server configurations</li> <li>GPU health, utilization, and thermal monitoring</li> <li>Support for GPU-enabled HPC applications</li> </ul>"},{"location":"machines-hardware-networks/#networking-infrastructure","title":"Networking Infrastructure","text":"<p>Reliable networking is critical for HPC performance and cluster stability. I work with both Ethernet and InfiniBand-based interconnects.</p>"},{"location":"machines-hardware-networks/#infiniband-networking","title":"InfiniBand Networking","text":"<ul> <li>NVIDIA InfiniBand QM9700 / QM9790 switches</li> <li>400 Gb/s InfiniBand fabric</li> <li>Fabric monitoring and issue resolution</li> <li>Link and port-level troubleshooting</li> </ul>"},{"location":"machines-hardware-networks/#ethernet-networking","title":"Ethernet Networking","text":"<ul> <li>Dell S3100 switches (1G / 10G)</li> <li>Network connectivity validation</li> <li>Support for management and service networks</li> </ul>"},{"location":"machines-hardware-networks/#hardware-management-monitoring","title":"Hardware Management &amp; Monitoring","text":"<p>I use enterprise hardware management and monitoring tools to maintain system health and availability.</p> <ul> <li>Dell OpenManage Enterprise (OME)</li> <li>NVIDIA Bright Cluster Manager</li> <li>InfiniBand UFM</li> </ul> <p>These tools are used for proactive fault detection, alert handling, and coordinated hardware maintenance.</p>"},{"location":"machines-hardware-networks/#datacenter-operations","title":"Datacenter Operations","text":"<p>I am involved in datacenter-level operational activities, including:</p> <ul> <li>Server rack mounting and physical integration</li> <li>Cabling coordination and validation</li> <li>BIOS, firmware, and driver upgrade cycles</li> <li>Hardware troubleshooting and vendor coordination</li> <li>Supporting infrastructure expansion and refresh activities</li> </ul>"},{"location":"professional-experience/","title":"Professional Experience","text":""},{"location":"professional-experience/#linux-systems-administrator","title":"Linux Systems Administrator","text":"<p>TIS Labs Pvt. Ltd., Kolkata January 2024 \u2013 Present</p> <p>I am responsible for the administration, operation, and reliability of large-scale Linux and high-performance computing (HPC) environments supporting mission-critical government and enterprise research workloads.</p> <p>My role involves day-to-day production support, cluster operations, performance validation, and infrastructure maintenance across CPU and GPU-based HPC systems.</p>"},{"location":"professional-experience/#key-responsibilities-contributions","title":"Key Responsibilities &amp; Contributions","text":"<ul> <li>Administered and supported large-scale HPC clusters comprising over 1,200 compute   nodes and GPU accelerator nodes with NVIDIA H100 GPUs, sustaining production   workloads at multi-petaflop scale.</li> <li>Managed HPC environments using NVIDIA Bright Cluster Manager, including cluster   provisioning, node lifecycle management, configuration updates, and system validation.</li> <li>Supported workload scheduling and job execution using PBS Pro, ensuring stable   and predictable job execution in shared environments.</li> <li>Performed continuous system monitoring and health checks using Bright Cluster   Manager, Dell OpenManage Enterprise, and InfiniBand UFM, contributing to   99.99% system availability.</li> <li>Executed OS provisioning, patching, and configuration management across compute   and management nodes in production environments.</li> <li>Automated routine administrative tasks using shell scripting, improving   operational efficiency and reducing manual intervention.</li> <li>Installed, configured, and validated commercial and open-source HPC applications   across multi-node environments, including MPI integration and environment module   configuration.</li> <li>Conducted performance benchmarking and validation using HPL, LINPACK, and   HPCC, ensuring systems met expected throughput and floating-point performance   targets.</li> <li>Supported 400 Gb/s InfiniBand networking, including fabric monitoring,   troubleshooting connectivity issues, and assisting with performance tuning.</li> <li>Performed hardware-level operations, including BIOS, firmware, and driver   upgrades on Dell PowerEdge servers, ensuring compliance with operational and   security standards.</li> <li>Provided 24\u00d77 L2 operational support, handling incident diagnosis, root-cause   analysis, corrective actions, and operational documentation.</li> <li>Contributed to BSNL datacenter modernization activities, supporting server   integration, network validation, and operating system provisioning across   multi-node environments.</li> </ul> <p>This role requires close coordination with infrastructure, networking, and application teams to ensure stable, secure, and high-performing HPC environments for production use.</p>"},{"location":"projects/","title":"Projects","text":"<p>This section outlines key projects where I contributed to the deployment, operation, and stabilization of large-scale HPC and datacenter infrastructure in production environments.</p>"},{"location":"projects/#indias-multi-petaflops-hpc-cluster-deployment","title":"India\u2019s Multi-Petaflops HPC Cluster Deployment","text":"<p>I was part of the core operations team supporting the deployment and sustained operation of a multi-petaflops high-performance computing environment used for national research and government workloads.</p>"},{"location":"projects/#scope-contributions","title":"Scope &amp; Contributions","text":"<ul> <li>Supported an HPC environment delivering approximately 11 Petaflops of compute   performance.</li> <li>Operated and administered clusters consisting of 1,200+ compute nodes and   NVIDIA H100 GPU accelerator nodes.</li> <li>Assisted with cluster provisioning and configuration using NVIDIA Bright   Cluster Manager.</li> <li>Supported workload scheduling and job execution through PBS Pro in shared   production environments.</li> <li>Performed system validation and performance benchmarking using HPL, LINPACK,   and HPCC to verify compute throughput and stability.</li> <li>Participated in production readiness checks, ensuring compute, network, and   monitoring components were operational before user onboarding.</li> <li>Supported 400 Gb/s InfiniBand fabric monitoring and troubleshooting during   cluster operation.</li> </ul> <p>This project required strict adherence to availability, performance, and operational standards due to its role in national research workloads.</p>"},{"location":"projects/#bsnl-datacenter-infrastructure-modernization","title":"BSNL Datacenter Infrastructure Modernization","text":"<p>I contributed to a large-scale datacenter modernization initiative supporting enterprise and HPC-ready infrastructure.</p>"},{"location":"projects/#scope-contributions_1","title":"Scope &amp; Contributions","text":"<ul> <li>Supported server installation and physical integration activities within the   datacenter environment.</li> <li>Performed operating system provisioning and validation across multiple nodes.</li> <li>Assisted with network connectivity checks and system readiness validation.</li> <li>Supported hardware configuration, firmware validation, and initial system   bring-up activities.</li> <li>Worked with infrastructure and networking teams to ensure smooth multi-node   deployment and operational handover.</li> </ul> <p>This project focused on improving infrastructure reliability, scalability, and readiness for high-performance and enterprise workloads.</p>"},{"location":"projects/#ongoing-operational-projects","title":"Ongoing Operational Projects","text":"<p>In addition to major deployments, I regularly contribute to operational initiatives, including:</p> <ul> <li>Cluster expansion and node onboarding</li> <li>Hardware refresh and firmware upgrade cycles</li> <li>Performance validation following system changes</li> <li>Automation improvements for provisioning and administration</li> <li>Incident-driven corrective actions and system improvements</li> </ul>"},{"location":"roles-responsibilities/","title":"Roles &amp; Responsibilities","text":"<p>This section defines my operational roles and responsibilities while supporting large-scale Linux and high-performance computing (HPC) environments in production.</p>"},{"location":"roles-responsibilities/#hpc-operations-administration","title":"HPC Operations &amp; Administration","text":"<ul> <li>Administer and support multi-petaflop HPC environments for government and enterprise   research workloads.</li> <li>Perform compute node provisioning, configuration, and lifecycle management.</li> <li>Support workload scheduling and execution using PBS Pro in shared HPC environments.</li> <li>Ensure stable and predictable job execution across CPU and GPU-based clusters.</li> </ul>"},{"location":"roles-responsibilities/#system-monitoring-reliability","title":"System Monitoring &amp; Reliability","text":"<ul> <li>Monitor system health and availability using NVIDIA Bright Cluster Manager,   Dell OpenManage Enterprise, and InfiniBand UFM.</li> <li>Perform proactive health checks to identify hardware, network, and system issues.</li> <li>Respond to alerts and incidents to minimize service disruption.</li> <li>Maintain high availability in 24\u00d77 production environments.</li> </ul>"},{"location":"roles-responsibilities/#performance-validation-optimization","title":"Performance Validation &amp; Optimization","text":"<ul> <li>Execute and analyze performance benchmarks using HPL, LINPACK, and HPCC.</li> <li>Validate compute throughput and floating-point performance after deployments,   upgrades, and configuration changes.</li> <li>Assist with performance tuning and baseline validation for production clusters.</li> </ul>"},{"location":"roles-responsibilities/#application-user-support","title":"Application &amp; User Support","text":"<ul> <li>Install, configure, and validate commercial and open-source HPC applications.</li> <li>Support MPI-based multi-node application execution.</li> <li>Manage environment modules and application runtime configurations.</li> <li>Provide user onboarding, access management, and technical support.</li> </ul>"},{"location":"roles-responsibilities/#automation-operational-efficiency","title":"Automation &amp; Operational Efficiency","text":"<ul> <li>Develop and maintain shell scripts for automation of routine administrative tasks.</li> <li>Automate OS provisioning, user management, and package deployment.</li> <li>Improve operational consistency and reduce manual intervention through scripting.</li> </ul>"},{"location":"roles-responsibilities/#hardware-infrastructure-support","title":"Hardware &amp; Infrastructure Support","text":"<ul> <li>Support server installation, integration, and validation in datacenter environments.</li> <li>Perform BIOS, firmware, and driver upgrades on Dell PowerEdge platforms.</li> <li>Assist with hardware diagnostics and issue resolution.</li> <li>Coordinate infrastructure changes during upgrades and expansions.</li> </ul>"},{"location":"roles-responsibilities/#networking-support","title":"Networking Support","text":"<ul> <li>Support high-speed InfiniBand (400 Gb/s) networking for HPC clusters.</li> <li>Monitor fabric health and resolve connectivity and performance issues.</li> <li>Validate network readiness for large-scale parallel workloads.</li> </ul>"},{"location":"roles-responsibilities/#incident-management-documentation","title":"Incident Management &amp; Documentation","text":"<ul> <li>Provide L2-level incident support in high-availability environments.</li> <li>Perform root-cause analysis and corrective actions for system issues.</li> <li>Document incidents, resolutions, and operational procedures.</li> <li>Support change implementation and validation activities.</li> </ul>"},{"location":"roles-responsibilities/#datacenter-project-support","title":"Datacenter &amp; Project Support","text":"<ul> <li>Contribute to datacenter modernization and infrastructure deployment projects.</li> <li>Support server mounting, OS provisioning, and network validation activities.</li> <li>Coordinate with cross-functional teams during project execution and handover.</li> </ul>"},{"location":"technical-skills/","title":"Technical Skills","text":"<p>This section outlines my technical skill set across Linux system administration, high-performance computing (HPC) operations, networking, automation, and datacenter infrastructure, aligned with production-grade enterprise environments.</p>"},{"location":"technical-skills/#operating-systems","title":"Operating Systems","text":"<ul> <li>Red Hat Enterprise Linux (RHEL) 9.x</li> <li>CentOS</li> <li>Linux system administration in multi-node environments</li> <li>OS installation, configuration, patching, and recovery</li> </ul>"},{"location":"technical-skills/#hpc-cluster-management-scheduling","title":"HPC Cluster Management &amp; Scheduling","text":"<ul> <li>NVIDIA Bright Cluster Manager</li> <li>PBS Pro</li> <li>Slurm (operational exposure)</li> </ul> <p>Activities include cluster provisioning, node lifecycle management, scheduler integration, job monitoring, and troubleshooting in production HPC environments.</p>"},{"location":"technical-skills/#gpu-accelerator-platforms","title":"GPU &amp; Accelerator Platforms","text":"<ul> <li>NVIDIA H100 GPU-based compute nodes</li> <li>GPU driver and CUDA stack validation</li> <li>GPU health, utilization, and thermal monitoring</li> <li>Support for multi-node GPU workloads</li> </ul>"},{"location":"technical-skills/#networking-interconnects","title":"Networking &amp; Interconnects","text":"<ul> <li>InfiniBand (QM9700 / QM9790 \u2013 400 Gb/s)</li> <li>Dell S3100 Ethernet switches (1G / 10G)</li> <li>InfiniBand fabric monitoring and issue resolution</li> <li>Network validation for HPC performance workloads</li> </ul>"},{"location":"technical-skills/#monitoring-management-tools","title":"Monitoring &amp; Management Tools","text":"<ul> <li>NVIDIA Bright Cluster Manager</li> <li>Dell OpenManage Enterprise (OME)</li> <li>InfiniBand UFM</li> </ul> <p>Used for system health monitoring, proactive fault detection, hardware alerts, and operational reliability.</p>"},{"location":"technical-skills/#benchmarking-performance-validation","title":"Benchmarking &amp; Performance Validation","text":"<ul> <li>HPL</li> <li>LINPACK</li> <li>HPCC</li> </ul> <p>Experience includes performance validation, baseline comparison, and throughput verification during deployment and production operations.</p>"},{"location":"technical-skills/#hpc-applications-software","title":"HPC Applications &amp; Software","text":""},{"location":"technical-skills/#commercial-applications","title":"Commercial Applications","text":"<ul> <li>ANSYS Fluent</li> <li>ANSYS CFX</li> <li>STAR-CCM+</li> <li>HEEDS</li> <li>Altair FEKO</li> </ul>"},{"location":"technical-skills/#open-source-applications","title":"Open-Source Applications","text":"<ul> <li>OpenFOAM</li> <li>SU2</li> <li>ParaView</li> </ul> <p>Includes installation, configuration, MPI integration, environment module setup, and runtime support in shared HPC environments.</p>"},{"location":"technical-skills/#compilers-libraries-mpi","title":"Compilers, Libraries &amp; MPI","text":"<ul> <li>AOCC</li> <li>AOCL</li> <li>GCC</li> <li>OpenMPI</li> <li>Intel OneAPI Toolkit</li> </ul> <p>Used for building, validating, and supporting application stacks across CPU and GPU nodes.</p>"},{"location":"technical-skills/#automation-scripting","title":"Automation &amp; Scripting","text":"<ul> <li>Shell / Bash scripting</li> <li>Automation of OS provisioning and configuration</li> <li>User onboarding and access setup</li> <li>Package deployment and environment module management</li> </ul>"},{"location":"technical-skills/#package-configuration-management","title":"Package &amp; Configuration Management","text":"<ul> <li>YUM</li> <li>RPM</li> <li>Repository configuration</li> <li>Dependency resolution in HPC environments</li> </ul>"},{"location":"technical-skills/#hardware-datacenter-operations","title":"Hardware &amp; Datacenter Operations","text":"<ul> <li>Dell PowerEdge servers (R6625, R7625, XE8640, T550)</li> <li>BIOS, firmware, and driver upgrades</li> <li>Hardware diagnostics and fault handling</li> <li>Server integration and validation</li> </ul>"},{"location":"technical-skills/#operations-support","title":"Operations &amp; Support","text":"<ul> <li>24\u00d77 L2 production support</li> <li>Incident diagnosis and root-cause analysis</li> <li>Change implementation and validation</li> <li>Operational documentation and handover support</li> </ul>"},{"location":"projects/testing/","title":"Project Details","text":""},{"location":"projects/testing/#indias-fastest-multi-petaflops-hpc-cluster-deployment","title":"India\u2019s Fastest Multi-Petaflops HPC Cluster Deployment","text":"<ul> <li>Key team member in deploying an 11 Petaflops HPC cluster</li> <li>Infrastructure included:</li> <li>1,241 compute nodes</li> <li>47 accelerator nodes</li> <li>4\u00d7 NVIDIA H100 GPUs per node</li> <li>Performed cluster validation and benchmarking using:</li> <li>HPL</li> <li>LINPACK</li> <li>HPCC</li> <li>Successfully exceeded all performance targets</li> </ul>"},{"location":"projects/testing/#bsnl-network-infrastructure-modernization","title":"BSNL Network Infrastructure Modernization","text":"<ul> <li>Contributed to large-scale datacenter hardware deployment</li> <li>Responsibilities included:</li> <li>Server mounting and cabling</li> <li>Network configuration and readiness checks</li> <li>OS installation and system validation</li> <li>Ensured stable multi-node operations in production environments</li> </ul>"},{"location":"projects/testing/#testing","title":"Testing","text":""}]}